# -*- coding: utf-8 -*-
"""Modelo_Sarima.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iAFMXztN6AvkjVaC3_b2wtbi-jGTxS8R
"""

import os
import pickle
import json
import warnings
from pathlib import Path

warnings.filterwarnings("ignore")

# ======================================================
# CONFIGURACI√ìN DE CARPETAS Y NOMBRES DE ARCHIVOS
# ======================================================
# Determinar la ruta base del proyecto
if __name__ == "__main__":
    # En GitHub Actions o ejecuci√≥n local
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
else:
    # En Colab
    BASE_DIR = "/content/drive/MyDrive" if 'IN_COLAB' in locals() and IN_COLAB else "."

# Carpeta para pron√≥sticos
PRONOSTICOS_DIR = os.path.join(BASE_DIR, "pronosticos")
os.makedirs(PRONOSTICOS_DIR, exist_ok=True)

print(f"üìÅ Carpeta de pron√≥sticos: {PRONOSTICOS_DIR}")

# Nombres fijos de archivos JSON
ARCHIVOS_JSON = {
    "Temperature": "pronostico_temperature.json",
    "Humidity": "pronostico_humidity.json", 
    "PM 2.5": "pronostico_pm25.json",
    "PM 10": "pronostico_pm10.json"
}

# ======================================================
# URL DE GOOGLE SHEETS (definida a nivel global)
# ======================================================
SHEET_URL = "https://docs.google.com/spreadsheets/d/1x1FeUolFWlR07tgrc6F4cgeUhJYV7uQ5yuRTBHO8jWI/edit?gid=0#gid=0"

# ======================================================
# 1. FUNCI√ìN DE CONEXI√ìN A GOOGLE SHEETS (COLAB + GITHUB)
# ======================================================


def conectar_a_google_sheets():
    """
    Conecta a Google Sheets de manera inteligente
    - En Colab: usa autenticaci√≥n normal
    - En GitHub: puede usar Service Account
    """

    try:
        # Verificar si estamos en Google Colab
        try:
            from google.colab import auth

            IN_COLAB = True
        except:
            IN_COLAB = False

        if IN_COLAB:
            # ========== MODO COLAB ==========
            print("üîë Autenticando en Google Colab...")

            # Autenticaci√≥n interactiva
            auth.authenticate_user()
            from google.auth import default

            creds, _ = default()

            # Guardar credenciales (opcional)
            with open("/content/token.pickle", "wb") as token:
                pickle.dump(creds, token)

            import gspread

            gc = gspread.authorize(creds)

        else:
            # ========== MODO GITHUB/LOCAL ==========
            import gspread

            # Intentar con variable de entorno (para GitHub Actions)
            creds_json = os.getenv("GOOGLE_SHEETS_CREDS")

            if creds_json:
                print("üîë Usando Service Account desde variable de entorno...")
                from google.oauth2.service_account import Credentials

                creds_dict = json.loads(creds_json)
                scope = ["https://www.googleapis.com/auth/spreadsheets"]
                credentials = Credentials.from_service_account_info(
                    creds_dict, scopes=scope
                )
                gc = gspread.authorize(credentials)
            else:
                # Intentar autenticaci√≥n normal (fallback)
                print("‚ö†Ô∏è  Intentando autenticaci√≥n normal...")
                gc = gspread.oauth()  # Esto abrir√° navegador en local

        # Abrir la hoja
        spreadsheet = gc.open_by_url(SHEET_URL)
        worksheet = spreadsheet.get_worksheet(0)

        print("‚úÖ Conexi√≥n exitosa a Google Sheets")
        return worksheet

    except Exception as e:
        print(f"‚ùå Error conectando a Google Sheets: {e}")
        print("‚ö†Ô∏è  Usando datos de ejemplo para continuar...")
        return None


# ======================================================
# 2. CONFIGURACI√ìN INICIAL DE COLAB
# ======================================================

# Montar Google Drive (solo funciona en Colab)
try:
    from google.colab import drive

    drive.mount("/content/drive", force_remount=False)
    IN_COLAB = True

    # Crear carpeta para pron√≥sticos
    os.makedirs("/content/drive/MyDrive/pronosticos", exist_ok=True)
    print("‚úÖ Google Drive montado y carpeta creada")

except:
    IN_COLAB = False
    print("‚ö†Ô∏è  No es Google Colab, omitiendo montaje de Drive")

# ======================================================
# 3. INSTALAR DEPENDENCIAS (SOLO COLAB)
# ======================================================

if IN_COLAB:
    print("üì¶ Instalando dependencias en Colab...")
else:
    print("‚úÖ En GitHub, las dependencias se instalan desde requirements.txt")

# ======================================================
# 4. IMPORTAR BIBLIOTECAS
# ======================================================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import gspread
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.statespace.sarimax import SARIMAX
import matplotlib.dates as mdates
from datetime import datetime, timedelta

# Cargar jupyter-black (solo Colab)
if IN_COLAB:
    import jupyter_black

    jupyter_black.load()

# ======================================================
# 5. REEMPLAZAR LA IMPORTACI√ìN DE 'direl_ts_tool_kit'
# ======================================================


def parse_datetime_index(df, date_column="date", format="%d/%m/%Y %H:%M:%S"):
    """
    Convierte una columna de fecha a datetime y la usa como √≠ndice
    (Reemplaza a la funci√≥n de direl_ts_tool_kit)
    """
    df_copy = df.copy()
    df_copy[date_column] = pd.to_datetime(
        df_copy[date_column], format=format, errors="coerce"
    )
    df_copy.set_index(date_column, inplace=True)
    return df_copy


def plot_time_series(df, variable, units="", time_unit="Day"):
    """
    Grafica una serie de tiempo
    (Versi√≥n simplificada de la funci√≥n original)
    """
    fig, ax = plt.subplots(figsize=(12, 5))

    ax.plot(df.index, df[variable], linewidth=1)
    ax.set_title(f"Serie de Tiempo - {variable}")
    ax.set_xlabel(f"Tiempo ({time_unit})")
    ax.set_ylabel(f"{variable} {units}")
    ax.grid(True, alpha=0.3)

    # Formato de fechas (usando formato para 2025-2026)
    date_format = "%d/%m/%Y %H:%M" if df.index[0].year >= 2025 else "%d/%m %H:%M"
    ax.xaxis.set_major_formatter(mdates.DateFormatter(date_format))
    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)

    plt.tight_layout()
    return fig

# ======================================================
# FUNCIONES PARA GUARDAR PRON√ìSTICOS EN JSON
# ======================================================
def guardar_pronostico_completo_json(serie_historica, pronostico_df, variable, carpeta_destino=PRONOSTICOS_DIR):
    """
    Guarda datos hist√≥ricos + pron√≥stico en un solo JSON con nombre fijo
    """
    try:
        # Verificar que tenemos datos
        if serie_historica.empty or pronostico_df.empty:
            print(f"‚ö†Ô∏è  Datos vac√≠os para {variable}, omitiendo guardado")
            return None
        
        # Obtener fecha actual REAL
        fecha_actual = datetime.now()
        
        # 1. Datos hist√≥ricos (√∫ltimas 168 horas = 7 d√≠as para contexto)
        historico_limitado = serie_historica.iloc[-168:] if len(serie_historica) > 168 else serie_historica
        
        historico = {}
        for idx, valor in historico_limitado.items():
            if isinstance(idx, pd.Timestamp):
                fecha_str = idx.isoformat()
            else:
                fecha_str = str(idx)
            historico[fecha_str] = float(valor)
        
        # 2. Pron√≥stico (72 horas)
        pronostico = {}
        for idx, valor in pronostico_df.items():
            if isinstance(idx, pd.Timestamp):
                fecha_str = idx.isoformat()
            else:
                fecha_str = str(idx)
            pronostico[fecha_str] = float(valor)
        
        # 3. Estad√≠sticas con fechas REALES
        stats = {
            "historico_puntos": len(historico_limitado),
            "pronostico_puntos": len(pronostico_df),
            "historico_horas": len(historico_limitado),
            "pronostico_horas": len(pronostico_df),
            "frecuencia": "horaria",
            "historico_inicio": serie_historica.index.min().isoformat() if len(serie_historica) > 0 else "N/A",
            "historico_fin": serie_historica.index.max().isoformat() if len(serie_historica) > 0 else "N/A",
            "pronostico_inicio": pronostico_df.index.min().isoformat() if len(pronostico_df) > 0 else "N/A",
            "pronostico_fin": pronostico_df.index.max().isoformat() if len(pronostico_df) > 0 else "N/A"
        }
        
        # 4. Estructura completa con fechas REALES
        resultado = {
            "variable": variable,
            "nombre_archivo": ARCHIVOS_JSON.get(variable, f"pronostico_{variable.lower().replace(' ', '_')}.json"),
            "fecha_generacion": fecha_actual.isoformat(),
            "unidad": obtener_unidad_variable(variable),
            "estadisticas": stats,
            "datos_historicos": historico,
            "pronostico": pronostico,
            "metadata": {
                "modelo": "SARIMA",
                "horizonte_pronostico": "72 horas",
                "fuente": "Google Sheets" if worksheet else "Datos de ejemplo",
                "periodo_historico": f"{stats['historico_inicio'].split('T')[0]} a {stats['historico_fin'].split('T')[0]}",
                "periodo_pronostico": f"{stats['pronostico_inicio'].split('T')[0]} a {stats['pronostico_fin'].split('T')[0]}",
                "actualizado": fecha_actual.strftime("%Y-%m-%d %H:%M:%S")
            }
        }
        
        # 5. Nombre del archivo (FIJO seg√∫n variable)
        nombre_archivo = ARCHIVOS_JSON.get(variable)
        if not nombre_archivo:
            # Fallback si la variable no est√° en el diccionario
            nombre_archivo = f"pronostico_{variable.lower().replace(' ', '_').replace('.', '')}.json"
        
        ruta_archivo = os.path.join(carpeta_destino, nombre_archivo)
        
        # 6. Guardar en JSON
        with open(ruta_archivo, 'w', encoding='utf-8') as f:
            json.dump(resultado, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ JSON guardado: {nombre_archivo}")
        print(f"   üìä Hist√≥rico: {len(historico)} puntos ({stats['historico_inicio'].split('T')[0]} a {stats['historico_fin'].split('T')[0]})")
        print(f"   üîÆ Pron√≥stico: {len(pronostico)} puntos ({stats['pronostico_inicio'].split('T')[0]} a {stats['pronostico_fin'].split('T')[0]})")
        
        return ruta_archivo
        
    except Exception as e:
        print(f"‚ùå Error guardando JSON para {variable}: {e}")
        import traceback
        traceback.print_exc()
        return None

def obtener_unidad_variable(variable):
    """Obtiene la unidad de medida para cada variable"""
    unidades = {
        "Temperature": "¬∞C",
        "Humidity": "%",
        "PM 2.5": "¬µg/m¬≥",
        "PM 10": "¬µg/m¬≥"
    }
    return unidades.get(variable, "unidades")

# ======================================================
# 6. CONECTAR Y CARGAR DATOS
# ======================================================

print("\n" + "=" * 60)
print("üì• CARGANDO DATOS DESDE GOOGLE SHEETS")
print("=" * 60)

# Conectar a Google Sheets
worksheet = conectar_a_google_sheets()

if worksheet is not None:
    # Obtener todos los datos
    datos = worksheet.get_all_values()

    # Convertir a DataFrame
    df0 = pd.DataFrame(datos[1:], columns=datos[0])

    print(f"‚úÖ Datos cargados desde Google Sheets")
    print(f"üìä Dimensiones: {df0.shape[0]} filas √ó {df0.shape[1]} columnas")
    print(f"üîó URL: {SHEET_URL}")

else:
    # ========== DATOS DE EJEMPLO (si falla la conexi√≥n) ==========
    print("üìù Usando datos de ejemplo para demostraci√≥n...")
    print("‚ö†Ô∏è  NOTA: Los datos reales comienzan desde 9 de noviembre de 2025")

    # Crear datos de ejemplo con fechas REALES (noviembre 2025 en adelante)
    import numpy as np
    
    # Fechas desde 9 de noviembre de 2025 (como tus datos reales)
    fechas = pd.date_range(start="2025-11-09", periods=500, freq="H")  # M√°s datos para ejemplo
    
    datos_ejemplo = {
        "Date": [f.strftime("%d/%m/%Y %H:%M:%S") for f in fechas],
        "Temperature": 25 + 5 * np.sin(np.linspace(0, 20, 500)),
        "Humidity": 60 + 10 * np.cos(np.linspace(0, 16, 500)),
        "PM 2.5(¬µg/m¬≥)": 20 + 8 * np.random.randn(500),
        "PM 10 (¬µg/m¬≥)": 40 + 12 * np.random.randn(500),
        "PM 1.0 (¬µg/m¬≥)": 10 + 4 * np.random.randn(500),
    }

    df0 = pd.DataFrame(datos_ejemplo)
    print(f"üìä Datos de ejemplo creados: {df0.shape[0]} filas")
    print(f"üìÖ Rango de fechas ejemplo: {fechas[0]} a {fechas[-1]}")

print("\nüìã Primeras filas de datos:")
print(df0.head(2))

# Renombrar columnas
df0.rename(
    columns={
        "Date": "date",
        "PM 1.0 (¬µg/m¬≥)": "PM 1",
        "PM 2.5(¬µg/m¬≥)": "PM 2.5",
        "PM 10 (¬µg/m¬≥)": "PM 10",
    },
    inplace=True,
)

# ======================================================
# CORRECCI√ìN: LIMPIAR DATOS ANTES DE CONVERSI√ìN
# ======================================================

print("üîç Limpiando y preparando datos...")

# 1. Identificar y eliminar columnas vac√≠as o no deseadas
columnas_originales = df0.columns.tolist()
print(f"Columnas originales: {columnas_originales}")

# Eliminar columnas que no contienen datos num√©ricos o est√°n vac√≠as
columnas_a_mantener = ["date", "Temperature", "Humidity", "PM 1", "PM 2.5", "PM 10"]
df0 = df0[columnas_a_mantener]

print(f"Columnas despu√©s de limpieza: {df0.columns.tolist()}")

# 2. Convertir columnas a num√©ricas
print("\nüìä Convirtiendo columnas a tipo num√©rico...")

for col in ["Temperature", "Humidity", "PM 1", "PM 2.5", "PM 10"]:
    if col in df0.columns:
        # Verificar valores √∫nicos antes de conversi√≥n
        valores_unicos = df0[col].unique()[:5]
        print(f"  {col}: {len(df0[col])} valores, primeros 5: {valores_unicos}")
        
        # Convertir, forzando errores a NaN
        df0[col] = pd.to_numeric(df0[col], errors='coerce')
        
        # Verificar despu√©s de conversi√≥n
        nans = df0[col].isna().sum()
        if nans > 0:
            print(f"    ‚ö†Ô∏è  {nans} valores convertidos a NaN")
        
        # Rellenar NaN con el valor anterior (forward fill)
        df0[col] = df0[col].fillna(method='ffill').fillna(method='bfill')

print("\n‚úÖ Tipos de datos despu√©s de conversi√≥n:")
print(df0.dtypes)

# ======================================================
# 7. PARSEAR FECHAS Y CREAR √çNDICE TEMPORAL
# ======================================================

print("\nüìÖ Parseando fechas...")
df1 = parse_datetime_index(df0, format="%d/%m/%Y %H:%M:%S")

# Verificar que todas las fechas sean v√°lidas
fechas_nulas = df1.index.isna().sum()
if fechas_nulas > 0:
    print(f"‚ö†Ô∏è  {fechas_nulas} fechas no pudieron ser parseadas")
    # Eliminar filas con fechas nulas
    df1 = df1[~df1.index.isna()]

# Mostrar informaci√≥n de fechas REALES
if len(df1) > 0:
    fecha_inicio = df1.index.min()
    fecha_fin = df1.index.max()
    print(f"‚úÖ √çndice temporal creado. Forma: {df1.shape}")
    print(f"   üìÖ Rango de fechas REALES: {fecha_inicio} a {fecha_fin}")
    print(f"   üìä D√≠as totales: {(fecha_fin - fecha_inicio).days} d√≠as")
    print(f"   üìà A√±o de los datos: {fecha_inicio.year}")
else:
    print("‚ùå No hay fechas v√°lidas despu√©s del parseo")

print(f"   üìã Columnas disponibles: {df1.columns.tolist()}")

# ======================================================
# 8. RESAMPLE CORREGIDO - USANDO SOLO COLUMNAS NUM√âRICAS
# ======================================================

print("\nüìä Realizando resample a 10 minutos...")

# Seleccionar solo columnas num√©ricas para el resample
columnas_numericas = df1.select_dtypes(include=[np.number]).columns.tolist()
print(f"Columnas num√©ricas para resample: {columnas_numericas}")

if len(columnas_numericas) > 0:
    # Crear un DataFrame con solo columnas num√©ricas para el resample
    df_numerico = df1[columnas_numericas]
    
    # Realizar resample solo en columnas num√©ricas
    df_resampled = df_numerico.resample("10min").mean()
    
    # Verificar que no haya valores nulos despu√©s del resample
    valores_nulos = df_resampled.isna().sum().sum()
    if valores_nulos > 0:
        print(f"‚ö†Ô∏è  {valores_nulos} valores nulos despu√©s del resample")
        # Rellenar valores nulos con interpolaci√≥n
        df_resampled = df_resampled.interpolate(method='time')
    
    print(f"‚úÖ Resample completado exitosamente")
    print(f"   Nueva forma: {df_resampled.shape[0]} filas √ó {df_resampled.shape[1]} columnas")
    print(f"   Rango: {df_resampled.index.min()} a {df_resampled.index.max()}")
    
    # Asignar de vuelta a df1
    df1 = df_resampled
else:
    print("‚ùå No hay columnas num√©ricas para realizar el resample")
    print("   Columnas disponibles:", df1.dtypes)
    # Crear un DataFrame vac√≠o para continuar
    df1 = pd.DataFrame(index=pd.date_range(start=df1.index.min(), periods=100, freq='10min'))

# Mostrar estad√≠sticas
print("\nüìà Estad√≠sticas descriptivas:")
print(df1.describe().transpose())

# ======================================================
# CONTINUAR CON EL C√ìDIGO ORIGINAL...
# ======================================================

print("\nüìä Visualizando series de tiempo originales...")
fig = plot_time_series(df1, variable="Temperature", units="¬∞C", time_unit="Day")
plt.title(f"Temperatura - Datos desde {df1.index.min().strftime('%d/%m/%Y')}")
plt.show()

fig = plot_time_series(df1, variable="Humidity", units="%", time_unit="Day")
plt.title(f"Humedad - Datos desde {df1.index.min().strftime('%d/%m/%Y')}")
plt.show()

if "PM 10" in df1.columns:
    fig = plot_time_series(df1, variable="PM 10", units="¬µg/m¬≥", time_unit="Day")
    plt.title(f"PM10 - Datos desde {df1.index.min().strftime('%d/%m/%Y')}")
    plt.show()

if "PM 2.5" in df1.columns:
    fig = plot_time_series(df1, variable="PM 2.5", units="¬µg/m¬≥", time_unit="Day")
    plt.title(f"PM2.5 - Datos desde {df1.index.min().strftime('%d/%m/%Y')}")
    plt.show()

df2 = df1.copy()

vars_to_impute = ["Temperature", "Humidity", "PM 10", "PM 2.5"]
# Filtrar solo las columnas que existen
vars_to_impute = [var for var in vars_to_impute if var in df2.columns]

for var in vars_to_impute:
    # Marcar NaN antes de imputar
    df2[f"{var}_imputed"] = df2[var].isna()

    # Calcular medias por hora:minuto
    means = df2.groupby(df2.index.time)[var].transform("mean")

    # Llenar SOLO los NaN, sin alterar valores originales
    df2[var] = df2[var].fillna(means)

df2 = df2.loc[:, ~df2.columns.str.endswith("_imputed")]
# Ver primeras filas del nuevo DataFrame
print(df2.head())

# Verificar datos imputados
imputed_cols = [col for col in df2.columns if "imputed" in col]
if imputed_cols:
    print(df2[imputed_cols].sum())
    df2 = df2.loc[:, ~df2.columns.str.endswith("_imputed")]
else:
    print("No hay columnas imputadas")

print("\nüìä Visualizando series de tiempo despu√©s de imputaci√≥n...")
fig = plot_time_series(df2, variable="Temperature", units="¬∞C", time_unit="Day")
plt.title(f"Temperatura (imputada) - Datos desde {df2.index.min().strftime('%d/%m/%Y')}")
plt.show()

fig = plot_time_series(df2, variable="Humidity", units="%", time_unit="Day")
plt.title(f"Humedad (imputada) - Datos desde {df2.index.min().strftime('%d/%m/%Y')}")
plt.show()

if "PM 10" in df2.columns:
    fig = plot_time_series(df2, variable="PM 10", units="¬µg/m¬≥", time_unit="Day")
    plt.title(f"PM10 (imputada) - Datos desde {df2.index.min().strftime('%d/%m/%Y')}")
    plt.show()

if "PM 2.5" in df2.columns:
    fig = plot_time_series(df2, variable="PM 2.5", units="¬µg/m¬≥", time_unit="Day")
    plt.title(f"PM2.5 (imputada) - Datos desde {df2.index.min().strftime('%d/%m/%Y')}")
    plt.show()

df3 = df2.copy()
# Eliminar los d√≠as 24 y 25
df3 = df3[~df3.index.day.isin([24, 25])]
if "PM 1" in df3.columns:
    df3 = df3.drop(columns=["PM 1"])
# Verificar los primeros registros
print(df3.head())

# Verificar los √∫ltimos registros para asegurarte que se eliminaron los d√≠as 19 y 20
print(df3.tail())

# ======================================================
# 1. RESAMPLEO A DATOS POR HORA
# ======================================================
df_hourly = df3.resample("H").mean().dropna()

variables = ["Temperature", "Humidity", "PM 2.5", "PM 10"]
# Filtrar solo las variables que existen en df_hourly
variables = [var for var in variables if var in df_hourly.columns]

print(f"\nüìà Variables disponibles para modelado: {variables}")
print(f"üìä Forma de datos horarios: {df_hourly.shape}")
print(f"üìÖ Rango temporal horario: {df_hourly.index.min()} a {df_hourly.index.max()}")

# ======================================================
# 2. OPTIMIZADOR SARIMA (SIN PMDARIMA)
# ======================================================
p = d = q = [0, 1]
P = D = Q = [0, 1]
m = 12  # estacionalidad de 12 horas


def buscar_mejor_modelo(series):
    mejor_aic = float("inf")
    mejor_modelo = None
    mejor_orden = None
    mejor_orden_season = None
    mejores_parametros = None
    mejor_summary = None

    for pi in p:
        for di in d:
            for qi in q:
                for Pi in P:
                    for Di in D:
                        for Qi in Q:
                            orden = (pi, di, qi)
                            orden_seas = (Pi, Di, Qi, m)

                            try:
                                modelo = SARIMAX(
                                    series,
                                    order=orden,
                                    seasonal_order=orden_seas,
                                    enforce_stationarity=False,
                                    enforce_invertibility=False,
                                ).fit(disp=False, maxiter=200)

                                if modelo.aic < mejor_aic:
                                    mejor_aic = modelo.aic
                                    mejor_modelo = modelo
                                    mejor_orden = orden
                                    mejor_orden_season = orden_seas
                                    mejores_parametros = modelo.params
                                    mejor_summary = modelo.summary()

                            except Exception as e:
                                # Silenciar errores de ajuste, continuar con siguiente combinaci√≥n
                                continue

    return (
        mejor_modelo,
        mejor_orden,
        mejor_orden_season,
        mejor_aic,
        mejores_parametros,
        mejor_summary,
    )

# ======================================================
# 3. FUNCI√ìN PARA OBTENER ECUACI√ìN MATEM√ÅTICA
# ======================================================
def obtener_ecuacion_sarima(modelo, orden, orden_seas):
    """
    Genera la ecuaci√≥n matem√°tica del modelo SARIMA
    """
    p, d, q = orden
    P, D, Q, m = orden_seas

    # Obtener par√°metros
    params = modelo.params

    # Inicializar partes de la ecuaci√≥n
    parte_ar = ""
    parte_ma = ""
    parte_sar = ""
    parte_sma = ""

    # Coeficientes AR (no estacional)
    for i in range(1, p + 1):
        if f"ar.L{i}" in params:
            coef = params[f"ar.L{i}"]
            parte_ar += f" + {coef:.4f}¬∑y_t-{i}"

    # Coeficientes MA (no estacional)
    for i in range(1, q + 1):
        if f"ma.L{i}" in params:
            coef = params[f"ma.L{i}"]
            parte_ma += f" + {coef:.4f}¬∑Œµ_t-{i}"

    # Coeficientes SAR (estacional)
    for i in range(1, P + 1):
        if f"ar.S.L{m*i}" in params:
            coef = params[f"ar.S.L{m*i}"]
            parte_sar += f" + {coef:.4f}¬∑y_t-{m*i}"

    # Coeficientes SMA (estacional)
    for i in range(1, Q + 1):
        if f"ma.S.L{m*i}" in params:
            coef = params[f"ma.S.L{m*i}"]
            parte_sma += f" + {coef:.4f}¬∑Œµ_t-{m*i}"

    # Constante
    constante = ""
    if "intercept" in params:
        constante = f"{params['intercept']:.4f} + "
    elif "const" in params:
        constante = f"{params['const']:.4f} + "

    # Construir ecuaci√≥n
    if d == 0 and D == 0:
        ecuacion = f"y_t = {constante}"
    else:
        # Para modelos con diferenciaci√≥n
        ecuacion = "Œî^d Œî_s^D y_t = "
        if constante.strip():
            ecuacion = f"Œî^d Œî_s^D y_t = {constante}"

    # Agregar partes
    if parte_ar:
        ecuacion += parte_ar[3:] if ecuacion.endswith("= ") else parte_ar
    if parte_ma:
        ecuacion += parte_ma
    if parte_sar:
        ecuacion += parte_sar
    if parte_sma:
        ecuacion += parte_sma

    if parte_ar or parte_ma or parte_sar or parte_sma:
        ecuacion += " + Œµ_t"
    else:
        ecuacion += "Œµ_t"

    return ecuacion

# ======================================================
# 4. FUNCI√ìN PARA MOSTRAR PAR√ÅMETROS COMO EN LA IMAGEN
# ======================================================
def mostrar_parametros_tabla(modelo, orden, orden_seas, aic):
    """
    Muestra los par√°metros en formato de tabla como en la imagen
    """
    params = modelo.params
    p, d, q = orden
    P, D, Q, m = orden_seas

    print("\n" + "=" * 60)
    print("PAR√ÅMETROS DEL MODELO SARIMA")
    print("=" * 60)

    # Crear lista de par√°metros
    parametros_lista = []

    # Par√°metros AR
    for i in range(1, p + 1):
        key = f"ar.L{i}"
        if key in params:
            parametros_lista.append((f"œÜ_{i}", params[key], modelo.bse.get(key, "N/A")))

    # Par√°metros MA
    for i in range(1, q + 1):
        key = f"ma.L{i}"
        if key in params:
            parametros_lista.append((f"Œ∏_{i}", params[key], modelo.bse.get(key, "N/A")))

    # Par√°metros SAR
    for i in range(1, P + 1):
        key = f"ar.S.L{m*i}"
        if key in params:
            parametros_lista.append((f"Œ¶_{i}", params[key], modelo.bse.get(key, "N/A")))

    # Par√°metros SMA
    for i in range(1, Q + 1):
        key = f"ma.S.L{m*i}"
        if key in params:
            parametros_lista.append((f"Œò_{i}", params[key], modelo.bse.get(key, "N/A")))

    # Constante
    if "intercept" in params:
        parametros_lista.append(
            ("intercept", params["intercept"], modelo.bse.get("intercept", "N/A"))
        )
    elif "const" in params:
        parametros_lista.append(
            ("const", params["const"], modelo.bse.get("const", "N/A"))
        )

    # Varianza del error
    if "sigma2" in params:
        parametros_lista.append(
            ("œÉ¬≤", params["sigma2"], modelo.bse.get("sigma2", "N/A"))
        )

    # Mostrar tabla
    print(f"\nOrden: SARIMA{orden}{orden_seas}")
    print(f"AIC: {aic:.2f}")
    print("\n" + "-" * 60)
    print(f"{'Par√°metro':<15} {'Valor':<15} {'Error est√°ndar':<15}")
    print("-" * 60)

    for nombre, valor, error in parametros_lista:
        if isinstance(error, (int, float)):
            print(f"{nombre:<15} {valor:<15.4f} {error:<15.4f}")
        else:
            print(f"{nombre:<15} {valor:<15.4f} {str(error):<15}")

    print("-" * 60)

# ======================================================
# 5. FUNCI√ìN PARA GRAFICAR PRON√ìSTICO CON FECHAS MEJORADAS
# ======================================================
def graficar_pronostico(modelo, series, pasos=48, limite=None):
    """
    Grafica el pron√≥stico SARIMA con manejo seguro de fechas
    Retorna el pron√≥stico como DataFrame para guardarlo
    """
    # Obtener pron√≥stico
    pred = modelo.get_forecast(steps=pasos)
    media = pred.predicted_mean
    conf_80 = pred.conf_int(alpha=0.20)
    conf_95 = pred.conf_int(alpha=0.05)
    
    # CR√çTICO: Asegurar que el √≠ndice del pron√≥stico sea datetime
    def ensure_datetime_index(index, reference_index=None):
        """Convierte un √≠ndice a DatetimeIndex si no lo es"""
        if isinstance(index, pd.DatetimeIndex):
            return index
        
        # Si el √≠ndice es entero, crear fechas basadas en referencia
        if reference_index is not None and isinstance(reference_index, pd.DatetimeIndex):
            last_date = reference_index[-1]
            freq = pd.infer_freq(reference_index) or 'H'
            
            # Crear nuevas fechas
            new_index = pd.date_range(
                start=last_date + pd.Timedelta(hours=1),
                periods=len(index),
                freq=freq
            )
            return new_index
        
        # Fallback: usar fechas gen√©ricas
        return pd.date_range(
            start=pd.Timestamp.now(),
            periods=len(index),
            freq='H'
        )
    
    # Asegurar que todos los √≠ndices sean DatetimeIndex
    if not isinstance(media.index, pd.DatetimeIndex):
        media.index = ensure_datetime_index(media.index, series.index)
        conf_80.index = media.index
        conf_95.index = media.index

    # Crear figura con tama√±o adecuado
    fig, ax = plt.subplots(figsize=(15, 6))

    # Datos hist√≥ricos (√∫ltimos 7 d√≠as para mejor visualizaci√≥n)
    historico_plot = series.iloc[-168:] if len(series) > 168 else series
    ax.plot(historico_plot.index, historico_plot.values, label="Hist√≥rico", color="black", linewidth=1.5)

    # Pron√≥stico
    ax.plot(
        media.index,
        media.values,
        label=f"Pron√≥stico {series.name}",
        color="red",
        linewidth=2,
    )

    # Bandas de confianza
    ax.fill_between(
        conf_80.index,
        conf_80.iloc[:, 0],
        conf_80.iloc[:, 1],
        color="green",
        alpha=0.3,
        label="Confianza 80%",
    )
    ax.fill_between(
        conf_95.index,
        conf_95.iloc[:, 0],
        conf_95.iloc[:, 1],
        color="yellow",
        alpha=0.2,
        label="Confianza 95%",
    )

    # L√≠nea vertical para separar historial de pron√≥stico
    ultimo_historial = series.index[-1]
    ax.axvline(x=ultimo_historial, color="gray", linestyle="--", alpha=0.7, linewidth=1)

    # L√≠nea de norma o l√≠mite permitido
    if limite is not None:
        ax.axhline(
            y=limite,
            color="blue",
            linestyle="--",
            linewidth=2,
            label="L√≠mite permitido (24H)",
        )

    # Configurar formato de fechas - MANEJO SEGURO con fechas 2025-2026
    try:
        # Intentar determinar el formato basado en el rango temporal
        fecha_min = historico_plot.index.min()
        fecha_max = media.index.max()
        
        if isinstance(fecha_min, pd.Timestamp) and isinstance(fecha_max, pd.Timestamp):
            dias_totales = (fecha_max - fecha_min).days
            
            if dias_totales <= 7:
                # Para rangos cortos, mostrar d√≠a, mes y hora
                ax.xaxis.set_major_formatter(mdates.DateFormatter("%d/%m %H:%M"))
                ax.xaxis.set_major_locator(mdates.HourLocator(interval=6))
            elif dias_totales <= 30:
                # Para rangos medios, mostrar d√≠a y mes
                ax.xaxis.set_major_formatter(mdates.DateFormatter("%d/%m"))
                ax.xaxis.set_major_locator(mdates.DayLocator(interval=2))
            else:
                # Para rangos largos, mostrar mes y a√±o
                ax.xaxis.set_major_formatter(mdates.DateFormatter("%m/%Y"))
                ax.xaxis.set_major_locator(mdates.MonthLocator())
        else:
            # Formato por defecto
            ax.xaxis.set_major_formatter(mdates.DateFormatter("%Y-%m-%d %H:%M"))
    except Exception as e:
        print(f"‚ö†Ô∏è  Advertencia al formatear fechas: {e}")
        # Formato por defecto seguro
        ax.xaxis.set_major_formatter(mdates.DateFormatter("%Y-%m-%d"))
    
    # Rotar etiquetas para mejor lectura
    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha="right")

    # Agregar leyenda de separaci√≥n
    try:
        if isinstance(ultimo_historial, pd.Timestamp):
            ax.text(
                ultimo_historial + pd.Timedelta(hours=1),
                ax.get_ylim()[1] * 0.95,
                "PRON√ìSTICO",
                fontsize=10,
                color="darkred",
                alpha=0.8,
                fontweight='bold'
            )
    except:
        pass  # Si falla, continuar sin el texto

    # T√≠tulos y etiquetas
    titulo_fecha = f"{ultimo_historial.strftime('%d/%m/%Y')}" if isinstance(ultimo_historial, pd.Timestamp) else ""
    ax.set_title(f"Pron√≥stico SARIMA - {series.name} (Generado: {datetime.now().strftime('%d/%m/%Y %H:%M')})", fontsize=14, fontweight="bold")
    ax.set_xlabel("Fecha y Hora", fontsize=12)

    # Etiqueta del eje Y dependiendo de la variable
    if series.name == "Temperature":
        ax.set_ylabel("Temperatura (¬∞C)", fontsize=12)
    elif series.name == "Humidity":
        ax.set_ylabel("Humedad (%)", fontsize=12)
    elif series.name in ["PM 2.5", "PM 10"]:
        ax.set_ylabel(f"{series.name} (¬µg/m¬≥)", fontsize=12)
    else:
        ax.set_ylabel(series.name, fontsize=12)

    # Cuadr√≠cula
    ax.grid(True, alpha=0.3, linestyle="--")

    # Leyenda
    ax.legend(loc="upper left", fontsize=10)

    # Ajustar m√°rgenes
    plt.tight_layout()
    
    # Retornar tanto la figura como los datos del pron√≥stico
    return fig, media

# ======================================================
# 6. EJECUCI√ìN COMPLETA POR VARIABLE
# ======================================================
limites = {
    "Temperature": None,
    "Humidity": None,
    "PM 2.5": 37,  # valor OMS o Colombia
    "PM 10": 75,
}

resultados = {}
ecuaciones = {}
parametros_tablas = {}
archivos_json_generados = {}

print(f"\n{'='*80}")
print(" INICIANDO GENERACI√ìN DE MODELOS SARIMA Y PRON√ìSTICOS")
print(f"{'='*80}")

for var in variables:
    print(f"\n{'='*80}")
    print(f" PROCESANDO: {var}")
    print(f"{'='*80}")

    serie = df_hourly[var]

    print(f"üìä Datos hist√≥ricos de {var}: {len(serie)} puntos")
    print(f"üìÖ Rango hist√≥rico REAL: {serie.index.min()} a {serie.index.max()}")

    modelo, orden, orden_s, aic, parametros, summary = buscar_mejor_modelo(serie)

    if modelo is None:
        print(f"‚ùå No se pudo ajustar un modelo SARIMA para {var}")
        continue

    print(f"\n‚úÖ Modelo encontrado para {var}: SARIMA{orden}{orden_s}")
    print(f"üìà AIC = {aic:.2f}")

    # Obtener y mostrar ecuaci√≥n matem√°tica
    ecuacion = obtener_ecuacion_sarima(modelo, orden, orden_s)
    print(f"\nüßÆ Ecuaci√≥n matem√°tica:")
    print(f"{ecuacion}")

    # Mostrar par√°metros en formato de tabla
    mostrar_parametros_tabla(modelo, orden, orden_s, aic)

    # Guardar resultados
    resultados[var] = modelo
    ecuaciones[var] = ecuacion
    parametros_tablas[var] = {
        "orden": orden,
        "orden_estacional": orden_s,
        "aic": aic,
        "parametros": parametros.to_dict() if hasattr(parametros, 'to_dict') else dict(parametros),
        "summary": str(summary) if summary else "No disponible"
    }

    # Graficar pron√≥stico (72 horas adelante)
    print(f"\nüìà Generando gr√°fica con hist√≥rico y pron√≥stico de 72 horas...")
    fig, pronostico_df = graficar_pronostico(modelo, serie, pasos=72, limite=limites.get(var))
    if fig:
        plt.show()
        
        # Guardar datos hist√≥ricos + pron√≥stico en JSON con nombre fijo
        ruta_json = guardar_pronostico_completo_json(serie, pronostico_df, var, PRONOSTICOS_DIR)
        if ruta_json:
            archivos_json_generados[var] = ruta_json
            print(f"‚úÖ JSON guardado exitosamente para {var}")

# ======================================================
# 7. CREAR ARCHIVO DE METADATOS GENERAL
# ======================================================
try:
    # Obtener fecha actual REAL
    fecha_actual = datetime.now()
    
    metadata = {
        "proyecto": "Modelo SARIMA - Pron√≥stico de Calidad del Aire y Variables Ambientales",
        "fecha_ejecucion": fecha_actual.isoformat(),
        "fecha_ejecucion_formateada": fecha_actual.strftime("%d/%m/%Y %H:%M:%S"),
        "fuente_datos": SHEET_URL if worksheet else "Datos de ejemplo",
        "periodo_pronostico_horas": 72,
        "frecuencia_datos": "Horaria",
        "variables_procesadas": variables,
        "archivos_generados": {},
        "carpeta_pronosticos": PRONOSTICOS_DIR,
        "modelos_ajustados": len(resultados),
        "rango_temporal_datos": f"{df_hourly.index.min().strftime('%d/%m/%Y')} a {df_hourly.index.max().strftime('%d/%m/%Y')}" if len(df_hourly) > 0 else "N/A",
        "ano_datos": df_hourly.index[0].year if len(df_hourly) > 0 else "N/A"
    }
    
    # Agregar informaci√≥n de cada archivo
    for var, ruta in archivos_json_generados.items():
        nombre_archivo = os.path.basename(ruta)
        if var in resultados:
            modelo_info = resultados[var]
            metadata["archivos_generados"][var] = {
                "archivo": nombre_archivo,
                "ruta_completa": ruta,
                "modelo": f"SARIMA{modelo_info.specification.order}{modelo_info.specification.seasonal_order}",
                "aic": float(modelo_info.aic),
                "observaciones": len(df_hourly[var])
            }
        else:
            metadata["archivos_generados"][var] = {
                "archivo": nombre_archivo,
                "ruta_completa": ruta,
                "modelo": "N/A",
                "aic": "N/A",
                "observaciones": len(df_hourly[var]) if var in df_hourly.columns else 0
            }
    
    ruta_metadata = os.path.join(PRONOSTICOS_DIR, "metadata_general.json")
    with open(ruta_metadata, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    print(f"\nüìã Metadata general guardada en: {ruta_metadata}")
    
except Exception as e:
    print(f"‚ö†Ô∏è  Error guardando metadata general: {e}")

# ======================================================
# 8. VERIFICAR Y MOSTRAR ARCHIVOS GENERADOS
# ======================================================
print(f"\n{'='*80}")
print(" üìÅ ARCHIVOS JSON GENERADOS EN LA CARPETA 'pronosticos'")
print(f"{'='*80}")

# Listar archivos en la carpeta pronosticos
archivos_en_carpeta = os.listdir(PRONOSTICOS_DIR) if os.path.exists(PRONOSTICOS_DIR) else []
archivos_json = [f for f in archivos_en_carpeta if f.endswith('.json')]

if archivos_json:
    print(f"\nüìã Total archivos JSON generados: {len(archivos_json)}")
    print("üìÇ Lista de archivos (con nombres fijos):")
    for archivo in sorted(archivos_json):
        ruta_completa = os.path.join(PRONOSTICOS_DIR, archivo)
        tamano = os.path.getsize(ruta_completa) if os.path.exists(ruta_completa) else 0
        fecha_mod = datetime.fromtimestamp(os.path.getmtime(ruta_completa)).strftime('%d/%m/%Y %H:%M') if os.path.exists(ruta_completa) else "N/A"
        print(f"   ‚Ä¢ {archivo} ({tamano/1024:.1f} KB, mod: {fecha_mod})")
else:
    print("‚ö†Ô∏è  No se encontraron archivos JSON en la carpeta")

# ======================================================
# 9. RESUMEN FINAL DE TODOS LOS MODELOS
# ======================================================
print(f"\n{'='*80}")
print(" üìä RESUMEN FINAL DE MODELOS SARIMA")
print(f"{'='*80}")

for var in variables:
    if var in resultados:
        modelo = resultados[var]
        print(f"\nüìà {var}:")
        print(f"   Modelo: SARIMA{modelo.specification.order}")
        print(f"           {modelo.specification.seasonal_order}")
        print(f"   AIC: {modelo.aic:.2f}")
        print(f"   Observaciones hist√≥ricas: {len(df_hourly[var])}")
        print(f"   Rango hist√≥rico: {df_hourly[var].index.min().strftime('%d/%m/%Y')} a {df_hourly[var].index.max().strftime('%d/%m/%Y')}")
        if var in archivos_json_generados:
            nombre_archivo = os.path.basename(archivos_json_generados[var])
            print(f"   Archivo JSON: {nombre_archivo}")
        
        # Mostrar primeros y √∫ltimos puntos del pron√≥stico
        if var in resultados:
            pred = resultados[var].get_forecast(steps=72)
            pronostico = pred.predicted_mean
            if len(pronostico) >= 2:
                fecha_inicio_pro = pronostico.index[0].strftime('%d/%m %H:%M') if isinstance(pronostico.index[0], pd.Timestamp) else str(pronostico.index[0])
                fecha_fin_pro = pronostico.index[-1].strftime('%d/%m %H:%M') if isinstance(pronostico.index[-1], pd.Timestamp) else str(pronostico.index[-1])
                print(f"   Pron√≥stico: {pronostico.iloc[0]:.2f} ‚Üí {pronostico.iloc[-1]:.2f} {obtener_unidad_variable(var)}")
                print(f"   Per√≠odo pron√≥stico: {fecha_inicio_pro} a {fecha_fin_pro}")

print(f"\n{'='*80}")
print(" ‚úÖ PROCESO COMPLETADO EXITOSAMENTE")
print(f"{'='*80}")

# ======================================================
# 10. MOSTRAR EJEMPLO DEL CONTENIDO JSON
# ======================================================
if archivos_json_generados:
    # Tomar el primer archivo como ejemplo
    primera_var = list(archivos_json_generados.keys())[0]
    ruta_ejemplo = archivos_json_generados[primera_var]
    
    try:
        with open(ruta_ejemplo, 'r', encoding='utf-8') as f:
            ejemplo = json.load(f)
        
        print(f"\nüìÑ EJEMPLO DE ESTRUCTURA JSON ({primera_var}):")
        print(f"   Variable: {ejemplo['variable']}")
        print(f"   Unidad: {ejemplo['unidad']}")
        print(f"   Puntos hist√≥ricos: {ejemplo['estadisticas']['historico_puntos']}")
        print(f"   Puntos pron√≥stico: {ejemplo['estadisticas']['pronostico_puntos']}")
        print(f"   Archivo: {ejemplo['nombre_archivo']}")
        print(f"   Per√≠odo hist√≥rico: {ejemplo['metadata']['periodo_historico']}")
        print(f"   Per√≠odo pron√≥stico: {ejemplo['metadata']['periodo_pronostico']}")
        
        # Mostrar ejemplos de datos
        print(f"\n   üìä Ejemplo datos hist√≥ricos (√∫ltimos 3):")
        historico = ejemplo['datos_historicos']
        fechas_hist = list(historico.keys())[-3:]
        for fecha in fechas_hist:
            valor = historico[fecha]
            fecha_obj = datetime.fromisoformat(fecha)
            fecha_formateada = fecha_obj.strftime('%d/%m/%Y %H:%M')
            print(f"     {fecha_formateada}: {valor:.2f} {ejemplo['unidad']}")
        
        print(f"\n   üîÆ Ejemplo datos pron√≥stico (primeros 3):")
        pronostico = ejemplo['pronostico']
        fechas_pro = list(pronostico.keys())[:3]
        for fecha in fechas_pro:
            valor = pronostico[fecha]
            fecha_obj = datetime.fromisoformat(fecha)
            fecha_formateada = fecha_obj.strftime('%d/%m/%Y %H:%M')
            print(f"     {fecha_formateada}: {valor:.2f} {ejemplo['unidad']}")
            
    except Exception as e:
        print(f"‚ö†Ô∏è  Error leyendo ejemplo JSON: {e}")

# Mensaje final
print(f"\n‚ú® Todos los archivos han sido guardados en: {PRONOSTICOS_DIR}")
print(f"üéØ Los gr√°ficos muestran datos hist√≥ricos REALES (desde noviembre 2025) y pron√≥sticos")
print(f"üìÅ Archivos JSON generados con nombres fijos:")
print(f"   ‚Ä¢ pronostico_temperature.json")
print(f"   ‚Ä¢ pronostico_humidity.json")
print(f"   ‚Ä¢ pronostico_pm25.json")
print(f"   ‚Ä¢ pronostico_pm10.json")
print(f"\nüìÖ A√±o de los datos: 2025-2026 (comenzando desde noviembre 2025)")

# -*- coding: utf-8 -*-
"""Modelo_Sarima.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iAFMXztN6AvkjVaC3_b2wtbi-jGTxS8R
"""

import os
import pickle
import json
import warnings

warnings.filterwarnings("ignore")

# ======================================================
# URL DE GOOGLE SHEETS (definida a nivel global)
# ======================================================
SHEET_URL = "https://docs.google.com/spreadsheets/d/1x1FeUolFWlR07tgrc6F4cgeUhJYV7uQ5yuRTBHO8jWI/edit?gid=0#gid=0"

# ======================================================
# 1. FUNCI√ìN DE CONEXI√ìN A GOOGLE SHEETS (COLAB + GITHUB)
# ======================================================


def conectar_a_google_sheets():
    """
    Conecta a Google Sheets de manera inteligente
    - En Colab: usa autenticaci√≥n normal
    - En GitHub: puede usar Service Account
    """

    try:
        # Verificar si estamos en Google Colab
        try:
            from google.colab import auth

            IN_COLAB = True
        except:
            IN_COLAB = False

        if IN_COLAB:
            # ========== MODO COLAB ==========
            print("üîë Autenticando en Google Colab...")

            # Autenticaci√≥n interactiva
            auth.authenticate_user()
            from google.auth import default

            creds, _ = default()

            # Guardar credenciales (opcional)
            with open("/content/token.pickle", "wb") as token:
                pickle.dump(creds, token)

            import gspread

            gc = gspread.authorize(creds)

        else:
            # ========== MODO GITHUB/LOCAL ==========
            import gspread

            # Intentar con variable de entorno (para GitHub Actions)
            creds_json = os.getenv("GOOGLE_SHEETS_CREDS")

            if creds_json:
                print("üîë Usando Service Account desde variable de entorno...")
                from google.oauth2.service_account import Credentials

                creds_dict = json.loads(creds_json)
                scope = ["https://www.googleapis.com/auth/spreadsheets"]
                credentials = Credentials.from_service_account_info(
                    creds_dict, scopes=scope
                )
                gc = gspread.authorize(credentials)
            else:
                # Intentar autenticaci√≥n normal (fallback)
                print("‚ö†Ô∏è  Intentando autenticaci√≥n normal...")
                gc = gspread.oauth()  # Esto abrir√° navegador en local

        # Abrir la hoja
        spreadsheet = gc.open_by_url(SHEET_URL)
        worksheet = spreadsheet.get_worksheet(0)

        print("‚úÖ Conexi√≥n exitosa a Google Sheets")
        return worksheet

    except Exception as e:
        print(f"‚ùå Error conectando a Google Sheets: {e}")
        print("‚ö†Ô∏è  Usando datos de ejemplo para continuar...")
        return None


# ======================================================
# 2. CONFIGURACI√ìN INICIAL DE COLAB
# ======================================================

# Montar Google Drive (solo funciona en Colab)
try:
    from google.colab import drive

    drive.mount("/content/drive", force_remount=False)
    IN_COLAB = True

    # Crear carpeta para pron√≥sticos
    os.makedirs("/content/drive/MyDrive/pronosticos", exist_ok=True)
    print("‚úÖ Google Drive montado y carpeta creada")

except:
    IN_COLAB = False
    print("‚ö†Ô∏è  No es Google Colab, omitiendo montaje de Drive")

# ======================================================
# 3. INSTALAR DEPENDENCIAS (SOLO COLAB)
# ======================================================

if IN_COLAB:
    print("üì¶ Instalando dependencias en Colab...")
else:
    print("‚úÖ En GitHub, las dependencias se instalan desde requirements.txt")

# ======================================================
# 4. IMPORTAR BIBLIOTECAS
# ======================================================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import gspread
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.statespace.sarimax import SARIMAX
import matplotlib.dates as mdates
from datetime import timedelta

# Cargar jupyter-black (solo Colab)
if IN_COLAB:
    import jupyter_black

    jupyter_black.load()

# ======================================================
# 5. REEMPLAZAR LA IMPORTACI√ìN DE 'direl_ts_tool_kit'
# ======================================================


def parse_datetime_index(df, date_column="date", format="%d/%m/%Y %H:%M:%S"):
    """
    Convierte una columna de fecha a datetime y la usa como √≠ndice
    (Reemplaza a la funci√≥n de direl_ts_tool_kit)
    """
    df_copy = df.copy()
    df_copy[date_column] = pd.to_datetime(
        df_copy[date_column], format=format, errors="coerce"
    )
    df_copy.set_index(date_column, inplace=True)
    return df_copy


def plot_time_series(df, variable, units="", time_unit="Day"):
    """
    Grafica una serie de tiempo
    (Versi√≥n simplificada de la funci√≥n original)
    """
    fig, ax = plt.subplots(figsize=(12, 5))

    ax.plot(df.index, df[variable], linewidth=1)
    ax.set_title(f"Serie de Tiempo - {variable}")
    ax.set_xlabel(f"Tiempo ({time_unit})")
    ax.set_ylabel(f"{variable} {units}")
    ax.grid(True, alpha=0.3)

    # Formato de fechas
    ax.xaxis.set_major_formatter(mdates.DateFormatter("%d/%m %H:%M"))
    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)

    plt.tight_layout()
    return fig


# ======================================================
# 6. CONECTAR Y CARGAR DATOS
# ======================================================

print("\n" + "=" * 60)
print("üì• CARGANDO DATOS DESDE GOOGLE SHEETS")
print("=" * 60)

# Conectar a Google Sheets
worksheet = conectar_a_google_sheets()

if worksheet is not None:
    # Obtener todos los datos
    datos = worksheet.get_all_values()

    # Convertir a DataFrame
    df0 = pd.DataFrame(datos[1:], columns=datos[0])

    print(f"‚úÖ Datos cargados desde Google Sheets")
    print(f"üìä Dimensiones: {df0.shape[0]} filas √ó {df0.shape[1]} columnas")
    print(f"üîó URL: {SHEET_URL}")

else:
    # ========== DATOS DE EJEMPLO (si falla la conexi√≥n) ==========
    print("üìù Usando datos de ejemplo para demostraci√≥n...")

    # Crear datos de ejemplo simples
    import numpy as np

    fechas = pd.date_range(start="2024-01-01", periods=100, freq="H")

    datos_ejemplo = {
        "Date": [f.strftime("%d/%m/%Y %H:%M:%S") for f in fechas],
        "Temperature": 25 + 5 * np.sin(np.linspace(0, 10, 100)),
        "Humidity": 60 + 10 * np.cos(np.linspace(0, 8, 100)),
        "PM 2.5(¬µg/m¬≥)": 20 + 8 * np.random.randn(100),
        "PM 10 (¬µg/m¬≥)": 40 + 12 * np.random.randn(100),
        "PM 1.0 (¬µg/m¬≥)": 10 + 4 * np.random.randn(100),
    }

    df0 = pd.DataFrame(datos_ejemplo)
    print(f"üìä Datos de ejemplo creados: {df0.shape[0]} filas")

print("\nüìã Primeras filas de datos:")
print(df0.head(2))

df0.rename(
    columns={
        "Date": "date",
        "PM 1.0 (¬µg/m¬≥)": "PM 1",
        "PM 2.5(¬µg/m¬≥)": "PM 2.5",
        "PM 10 (¬µg/m¬≥)": "PM 10",
    },
    inplace=True,
)

# ======================================================
# CONVERSI√ìN DE DATOS Y LIMPIEZA
# ======================================================

print("üîç Verificando tipos de datos iniciales:")
print(df0.dtypes)

# Identificar columnas que deber√≠an ser num√©ricas
columnas_numericas = ["Temperature", "Humidity", "PM 2.5", "PM 10", "PM 1"]

# Convertir cada columna a num√©rico, forzando errores a NaN
for col in columnas_numericas:
    if col in df0.columns:
        print(f"\nConvirtiendo columna '{col}'...")
        
        # Guardar valores originales para comparar
        valores_originales = df0[col].head(5).tolist()
        
        # Convertir a num√©rico
        df0[col] = pd.to_numeric(df0[col], errors='coerce')
        
        # Contar valores convertidos y no convertidos
        total_valores = len(df0[col])
        valores_nan = df0[col].isna().sum()
        valores_convertidos = total_valores - valores_nan
        
        print(f"  Valores originales (primeros 5): {valores_originales}")
        print(f"  Valores convertidos: {valores_convertidos}/{total_valores}")
        print(f"  Valores no convertidos (NaN): {valores_nan}")

# Crear DataFrame con √≠ndice temporal
df1 = parse_datetime_index(df0, format="%d/%m/%Y %H:%M:%S")

print("\n‚úÖ Tipos de datos despu√©s de la conversi√≥n:")
print(df1.dtypes)

# ======================================================
# LIMPIEZA ADICIONAL ANTES DEL RESAMPLE (SOLUCI√ìN AL ERROR)
# ======================================================

print("\nüßπ Realizando limpieza adicional antes del resample...")

# 1. Eliminar columnas vac√≠as o con nombres vac√≠os
df1 = df1.loc[:, ~df1.columns.astype(str).str.contains('^Unnamed')]
df1 = df1.loc[:, ~df1.columns.astype(str).str.contains('^$')]

# 2. Seleccionar solo columnas num√©ricas conocidas
columnas_a_mantener = ['Temperature', 'Humidity', 'PM 1', 'PM 2.5', 'PM 10']
columnas_existentes = [col for col in columnas_a_mantener if col in df1.columns]

print(f"üìã Columnas a mantener: {columnas_existentes}")

# 3. Verificar que todas las columnas sean num√©ricas
for col in columnas_existentes:
    if df1[col].dtype not in ['int64', 'float64']:
        print(f"‚ö†Ô∏è  Columna '{col}' no es num√©rica, convirtiendo...")
        df1[col] = pd.to_numeric(df1[col], errors='coerce')

# 4. Eliminar filas donde todas las columnas sean NaN
df1 = df1.dropna(how='all')

print(f"\nüìä DataFrame despu√©s de limpieza:")
print(f"  - Forma: {df1.shape[0]} filas √ó {df1.shape[1]} columnas")
print(f"  - Tipos de datos: {df1.dtypes.to_dict()}")

# ======================================================
# RESAMPLE CON SEGURIDAD
# ======================================================

print("\nüìä Realizando resample a 10 minutos...")
try:
    # Opci√≥n 1: Usar numeric_only=True para seguridad
    df1 = df1.resample("10min").mean(numeric_only=True)
    print("‚úÖ Resample completado exitosamente con numeric_only=True")
    
except Exception as e:
    print(f"‚ö†Ô∏è  Error con numeric_only=True: {e}")
    print("üîÑ Intentando m√©todo alternativo...")
    
    # Opci√≥n 2: M√©todo alternativo manual
    try:
        # Crear lista para almacenar resultados
        resample_data = []
        
        # Para cada columna num√©rica
        for col in df1.columns:
            if df1[col].dtype in ['int64', 'float64']:
                # Resample por columna
                col_resampled = df1[col].resample("10min").mean()
                resample_data.append(col_resampled)
        
        # Combinar resultados
        df1 = pd.concat(resample_data, axis=1)
        print("‚úÖ Resample completado exitosamente con m√©todo alternativo")
        
    except Exception as e2:
        print(f"‚ùå Error en m√©todo alternativo: {e2}")
        print("‚ö†Ô∏è  Continuando sin resample...")
        # Mantener df1 sin cambios

print(f"üìä Nueva forma despu√©s del resample: {df1.shape[0]} filas √ó {df1.shape[1]} columnas")

# Mostrar estad√≠sticas
print("\nüìà Estad√≠sticas descriptivas:")
print(df1.describe().transpose())

fig = plot_time_series(df1, variable="Temperature", units="¬∞C", time_unit="Day")
plt.show()

fig = plot_time_series(df1, variable="Humidity", units="%", time_unit="Day")
plt.show()

fig = plot_time_series(df1, variable="PM 10", units="¬µg/m¬≥", time_unit="Day")
plt.show()

fig = plot_time_series(df1, variable="PM 2.5", units="¬µg/m¬≥", time_unit="Day")
plt.show()

df2 = df1.copy()

vars_to_impute = ["Temperature", "Humidity", "PM 10", "PM 2.5"]

for var in vars_to_impute:
    # Marcar NaN antes de imputar
    df2[f"{var}_imputed"] = df2[var].isna()

    # Calcular medias por hora:minuto
    means = df2.groupby(df2.index.time)[var].transform("mean")

    # Llenar SOLO los NaN, sin alterar valores originales
    df2[var] = df2[var].fillna(means)

df2 = df2.loc[:, ~df2.columns.str.endswith("_imputed")]
# Ver primeras filas del nuevo DataFrame
print(df2.head())

# Ver solo los datos imputados de cada variable
print(df2[[col for col in df2.columns if "imputed" in col]].sum())
df2 = df2.loc[:, ~df2.columns.str.endswith("_imputed")]

fig = plot_time_series(df2, variable="Temperature", units="¬∞C", time_unit="Day")
plt.show()

fig = plot_time_series(df2, variable="Humidity", units="%", time_unit="Day")
plt.show()

fig = plot_time_series(df2, variable="PM 10", units="¬µg/m¬≥", time_unit="Day")
plt.show()

fig = plot_time_series(df2, variable="PM 2.5", units="¬µg/m¬≥", time_unit="Day")
plt.show()

df3 = df2.copy()
# Eliminar los d√≠as 24 y 25
df3 = df3[~df3.index.day.isin([24, 25])]
df3 = df3.drop(columns=["PM 1"])
# Verificar los primeros registros
print(df3.head())

# Verificar los √∫ltimos registros para asegurarte que se eliminaron los d√≠as 19 y 20
print(df3.tail())

# ======================================================
# 1. RESAMPLEO A DATOS POR HORA
# ======================================================
df_hourly = df3.resample("H").mean().dropna()

variables = ["Temperature", "Humidity", "PM 2.5", "PM 10"]

# ======================================================
# 2. OPTIMIZADOR SARIMA (SIN PMDARIMA)
# ======================================================
p = d = q = [0, 1]
P = D = Q = [0, 1]
m = 12  # estacionalidad de 12 horas


def buscar_mejor_modelo(series):
    mejor_aic = float("inf")
    mejor_modelo = None
    mejor_orden = None
    mejor_orden_season = None
    mejores_parametros = None
    mejor_summary = None

    for pi in p:
        for di in d:
            for qi in q:
                for Pi in P:
                    for Di in D:
                        for Qi in Q:
                            orden = (pi, di, qi)
                            orden_seas = (Pi, Di, Qi, m)

                            try:
                                modelo = SARIMAX(
                                    series,
                                    order=orden,
                                    seasonal_order=orden_seas,
                                    enforce_stationarity=False,
                                    enforce_invertibility=False,
                                ).fit(disp=False, maxiter=200)

                                if modelo.aic < mejor_aic:
                                    mejor_aic = modelo.aic
                                    mejor_modelo = modelo
                                    mejor_orden = orden
                                    mejor_orden_season = orden_seas
                                    mejores_parametros = modelo.params
                                    mejor_summary = modelo.summary()

                            except:
                                continue

    return (
        mejor_modelo,
        mejor_orden,
        mejor_orden_season,
        mejor_aic,
        mejores_parametros,
        mejor_summary,
    )

# ======================================================
# 3. FUNCI√ìN PARA OBTENER ECUACI√ìN MATEM√ÅTICA
# ======================================================
def obtener_ecuacion_sarima(modelo, orden, orden_seas):
    """
    Genera la ecuaci√≥n matem√°tica del modelo SARIMA
    """
    p, d, q = orden
    P, D, Q, m = orden_seas

    # Obtener par√°metros
    params = modelo.params

    # Inicializar partes de la ecuaci√≥n
    parte_ar = ""
    parte_ma = ""
    parte_sar = ""
    parte_sma = ""

    # Coeficientes AR (no estacional)
    for i in range(1, p + 1):
        if f"ar.L{i}" in params:
            coef = params[f"ar.L{i}"]
            parte_ar += f" + {coef:.4f}¬∑y_t-{i}"

    # Coeficientes MA (no estacional)
    for i in range(1, q + 1):
        if f"ma.L{i}" in params:
            coef = params[f"ma.L{i}"]
            parte_ma += f" + {coef:.4f}¬∑Œµ_t-{i}"

    # Coeficientes SAR (estacional)
    for i in range(1, P + 1):
        if f"ar.S.L{m*i}" in params:
            coef = params[f"ar.S.L{m*i}"]
            parte_sar += f" + {coef:.4f}¬∑y_t-{m*i}"

    # Coeficientes SMA (estacional)
    for i in range(1, Q + 1):
        if f"ma.S.L{m*i}" in params:
            coef = params[f"ma.S.L{m*i}"]
            parte_sma += f" + {coef:.4f}¬∑Œµ_t-{m*i}"

    # Constante
    constante = ""
    if "intercept" in params:
        constante = f"{params['intercept']:.4f} + "
    elif "const" in params:
        constante = f"{params['const']:.4f} + "

    # Construir ecuaci√≥n
    if d == 0 and D == 0:
        ecuacion = f"y_t = {constante}"
    else:
        # Para modelos con diferenciaci√≥n
        ecuacion = "Œî^d Œî_s^D y_t = "
        if constante.strip():
            ecuacion = f"Œî^d Œî_s^D y_t = {constante}"

    # Agregar partes
    if parte_ar:
        ecuacion += parte_ar[3:] if ecuacion.endswith("= ") else parte_ar
    if parte_ma:
        ecuacion += parte_ma
    if parte_sar:
        ecuacion += parte_sar
    if parte_sma:
        ecuacion += parte_sma

    if parte_ar or parte_ma or parte_sar or parte_sma:
        ecuacion += " + Œµ_t"
    else:
        ecuacion += "Œµ_t"

    return ecuacion

# ======================================================
# 4. FUNCI√ìN PARA MOSTRAR PAR√ÅMETROS COMO EN LA IMAGEN
# ======================================================
def mostrar_parametros_tabla(modelo, orden, orden_seas, aic):
    """
    Muestra los par√°metros en formato de tabla como en la imagen
    """
    params = modelo.params
    p, d, q = orden
    P, D, Q, m = orden_seas

    print("\n" + "=" * 60)
    print("PAR√ÅMETROS DEL MODELO SARIMA")
    print("=" * 60)

    # Crear lista de par√°metros
    parametros_lista = []

    # Par√°metros AR
    for i in range(1, p + 1):
        key = f"ar.L{i}"
        if key in params:
            parametros_lista.append((f"œÜ_{i}", params[key], modelo.bse.get(key, "N/A")))

    # Par√°metros MA
    for i in range(1, q + 1):
        key = f"ma.L{i}"
        if key in params:
            parametros_lista.append((f"Œ∏_{i}", params[key], modelo.bse.get(key, "N/A")))

    # Par√°metros SAR
    for i in range(1, P + 1):
        key = f"ar.S.L{m*i}"
        if key in params:
            parametros_lista.append((f"Œ¶_{i}", params[key], modelo.bse.get(key, "N/A")))

    # Par√°metros SMA
    for i in range(1, Q + 1):
        key = f"ma.S.L{m*i}"
        if key in params:
            parametros_lista.append((f"Œò_{i}", params[key], modelo.bse.get(key, "N/A")))

    # Constante
    if "intercept" in params:
        parametros_lista.append(
            ("intercept", params["intercept"], modelo.bse.get("intercept", "N/A"))
        )
    elif "const" in params:
        parametros_lista.append(
            ("const", params["const"], modelo.bse.get("const", "N/A"))
        )

    # Varianza del error
    if "sigma2" in params:
        parametros_lista.append(
            ("œÉ¬≤", params["sigma2"], modelo.bse.get("sigma2", "N/A"))
        )

    # Mostrar tabla
    print(f"\nOrden: SARIMA{orden}{orden_seas}")
    print(f"AIC: {aic:.2f}")
    print("\n" + "-" * 60)
    print(f"{'Par√°metro':<15} {'Valor':<15} {'Error est√°ndar':<15}")
    print("-" * 60)

    for nombre, valor, error in parametros_lista:
        if isinstance(error, (int, float)):
            print(f"{nombre:<15} {valor:<15.4f} {error:<15.4f}")
        else:
            print(f"{nombre:<15} {valor:<15.4f} {str(error):<15}")

    print("-" * 60)

# ======================================================
# 5. FUNCI√ìN PARA GRAFICAR PRON√ìSTICO CON FECHAS MEJORADAS
# ======================================================
def graficar_pronostico(modelo, series, pasos=48, limite=None):
    pred = modelo.get_forecast(steps=pasos)
    media = pred.predicted_mean
    conf_80 = pred.conf_int(alpha=0.20)
    conf_95 = pred.conf_int(alpha=0.05)

    # Crear figura con tama√±o adecuado
    fig, ax = plt.subplots(figsize=(15, 6))

    # Datos hist√≥ricos
    ax.plot(series.index, series.values, label="Medido", color="black", linewidth=1.5)

    # Pron√≥stico
    ax.plot(
        media.index,
        media.values,
        label=f"Pron√≥stico {series.name}",
        color="red",
        linewidth=2,
    )

    # Bandas de confianza
    ax.fill_between(
        conf_80.index,
        conf_80.iloc[:, 0],
        conf_80.iloc[:, 1],
        color="green",
        alpha=0.3,
        label="Confianza 80%",
    )
    ax.fill_between(
        conf_95.index,
        conf_95.iloc[:, 0],
        conf_95.iloc[:, 1],
        color="yellow",
        alpha=0.2,
        label="Confianza 95%",
    )

    # L√≠nea vertical para separar historial de pron√≥stico
    ultimo_historial = series.index[-1]
    ax.axvline(x=ultimo_historial, color="gray", linestyle="--", alpha=0.7, linewidth=1)

    # L√≠nea de norma o l√≠mite permitido
    if limite is not None:
        ax.axhline(
            y=limite,
            color="blue",
            linestyle="--",
            linewidth=2,
            label="Nivel m√°ximo permitido (24H) en Colombia",
        )

    # Configurar formato de fechas
    # Determinar el rango de fechas
    fecha_min = series.index.min()
    fecha_max = media.index.max()

    # Calcular diferencia de d√≠as para determinar el formato
    dias_totales = (fecha_max - fecha_min).days

    if dias_totales <= 7:  # Si es menos de una semana
        # Formato: D√≠a Hora (ej: "11 Nov 10:00")
        ax.xaxis.set_major_formatter(mdates.DateFormatter("%d %b %H:%M"))
        ax.xaxis.set_major_locator(mdates.HourLocator(interval=6))
    elif dias_totales <= 30:  # Si es menos de un mes
        # Formato: D√≠a Mes (ej: "11 Nov")
        ax.xaxis.set_major_formatter(mdates.DateFormatter("%d %b"))
        ax.xaxis.set_major_locator(mdates.DayLocator(interval=2))
    else:  # Si es m√°s de un mes
        # Formato: Mes (ej: "Nov 2025")
        ax.xaxis.set_major_formatter(mdates.DateFormatter("%b %Y"))
        ax.xaxis.set_major_locator(mdates.MonthLocator())

    # Rotar etiquetas para mejor lectura
    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha="right")

    # Agregar leyenda de separaci√≥n
    ax.text(
        ultimo_historial + timedelta(hours=1),
        ax.get_ylim()[1] * 0.95,
        "Pron√≥stico",
        fontsize=10,
        color="darkred",
        alpha=0.8,
    )

    # T√≠tulos y etiquetas
    ax.set_title(f"Pron√≥stico SARIMA - {series.name}", fontsize=14, fontweight="bold")
    ax.set_xlabel("Fecha y Hora", fontsize=12)

    # Etiqueta del eje Y dependiendo de la variable
    if series.name == "Temperature":
        ax.set_ylabel("Temperatura (¬∞C)", fontsize=12)
    elif series.name == "Humidity":
        ax.set_ylabel("Humedad (%)", fontsize=12)
    elif series.name in ["PM 2.5", "PM 10"]:
        ax.set_ylabel(f"{series.name} (¬µg/m¬≥)", fontsize=12)
    else:
        ax.set_ylabel(series.name, fontsize=12)

    # Cuadr√≠cula
    ax.grid(True, alpha=0.3, linestyle="--")

    # Leyenda
    ax.legend(loc="upper left", fontsize=10)

    # Ajustar m√°rgenes
    plt.tight_layout()

    plt.show()



# ======================================================
# 6. EJECUCI√ìN COMPLETA POR VARIABLE
# ======================================================
limites = {
    "Temperature": None,
    "Humidity": None,
    "PM 2.5": 37,  # valor OMS o Colombia
    "PM 10": 75,
}

resultados = {}
ecuaciones = {}
parametros_tablas = {}

for var in variables:
    print(f"\n{'='*80}")
    print(f" OPTIMIZANDO: {var}")
    print(f"{'='*80}")

    serie = df_hourly[var]

    modelo, orden, orden_s, aic, parametros, summary = buscar_mejor_modelo(serie)

    print(f"\nMejor modelo para {var}: SARIMA{orden}{orden_s}")
    print(f"AIC = {aic:.2f}")

    # Obtener y mostrar ecuaci√≥n matem√°tica
    ecuacion = obtener_ecuacion_sarima(modelo, orden, orden_s)
    print(f"\nEcuaci√≥n matem√°tica:")
    print(f"{ecuacion}")

    # Mostrar par√°metros en formato de tabla
    mostrar_parametros_tabla(modelo, orden, orden_s, aic)

    # Guardar resultados
    resultados[var] = modelo
    ecuaciones[var] = ecuacion
    parametros_tablas[var] = {
        "orden": orden,
        "orden_estacional": orden_s,
        "aic": aic,
        "parametros": parametros,
        "summary": summary,
    }

    # Graficar pron√≥stico (72 horas adelante)
    graficar_pronostico(modelo, serie, pasos=72, limite=limites[var])

# ======================================================
# 7. RESUMEN FINAL DE TODOS LOS MODELOS
# ======================================================
print(f"\n{'='*80}")
print(" RESUMEN FINAL DE MODELOS SARIMA")
print(f"{'='*80}")

for var in variables:
    print(f"\n{var}:")
    print(f"  Modelo: SARIMA{resultados[var].specification.order}")
    print(f"          {resultados[var].specification.seasonal_order}")
    print(f"  AIC: {resultados[var].aic:.2f}")
    print(f"  Ecuaci√≥n: {ecuaciones[var]}")
    print(f"  N√∫mero de observaciones: {len(df_hourly[var])}")
